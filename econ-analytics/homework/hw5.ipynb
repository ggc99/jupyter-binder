{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21d1e83c-9b58-4e42-b475-fa9551ae12ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <font color='darkred'> HW5\n",
    "    \n",
    "* Use the dataset, \"Hitters.csv\", posted on BB to explain/predict a baseball playerâ€™s salary <u> using a subset of covariates in the dataset </u>.\n",
    "    \n",
    "* In order to select a subset of covariates, do the following:\n",
    "    - Forward and backward stepwise selections based on AIC and BIC\n",
    "    - LASSO Estimations with CV, AIC and BIC\n",
    "    - Produce tables or figures or both to summarize your results\n",
    "    \n",
    "* For this exercise, you need to take care of missing values and also generate dummies for some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970157b8-a36c-46db-845c-faaa1c8c96f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Read data\n",
    "raw0 =pd.read_csv('../data/Hitters.csv')\n",
    "\n",
    "# Convert variables to dummies\n",
    "raw0 = pd.get_dummies(raw0.iloc[:,1:])\n",
    "\n",
    "# Drop rows with NaN\n",
    "raw_data = raw0.dropna()\n",
    "\n",
    "col_names = raw0.columns\n",
    "\n",
    "X_col = list(col_names[:16]) + list(col_names[17:])\n",
    "Y_col = 'Salary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "710e4cd4-ab31-4b49-9b54-283df58c86ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  ...  \\\n",
      "1    315    81      7    24   38     39     14    3449    835      69  ...   \n",
      "2    479   130     18    66   72     76      3    1624    457      63  ...   \n",
      "3    496   141     20    65   78     37     11    5628   1575     225  ...   \n",
      "4    321    87     10    39   42     30      2     396    101      12  ...   \n",
      "5    594   169      4    74   51     35     11    4408   1133      19  ...   \n",
      "\n",
      "   PutOuts  Assists  Errors  Salary  League_A  League_N  Division_E  \\\n",
      "1      632       43      10   475.0         0         1           0   \n",
      "2      880       82      14   480.0         1         0           0   \n",
      "3      200       11       3   500.0         0         1           1   \n",
      "4      805       40       4    91.5         0         1           1   \n",
      "5      282      421      25   750.0         1         0           0   \n",
      "\n",
      "   Division_W  NewLeague_A  NewLeague_N  \n",
      "1           1            0            1  \n",
      "2           1            1            0  \n",
      "3           0            0            1  \n",
      "4           0            0            1  \n",
      "5           1            1            0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(raw_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ce8b8f-30b4-41be-87a5-13b4cfceed3c",
   "metadata": {},
   "source": [
    "## <font color='Blue'> Forward Selection and Backward Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "602d7747-07ad-441d-9ef4-44026e2b1ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Initalize variables\n",
    "Y = raw_data[Y_col].values\n",
    "X = raw_data[X_col].values\n",
    "ncol = ncol=X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b81b2-5dc0-4733-be1e-c28b208e982e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Forward Selection BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586d6bbe-d75f-4ea5-95fe-89a76365ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcand = list(range(ncol)) # A list to keep track of the set of predictors left to add to the model at each iteration\n",
    "psel = [] # A list to keep track of the selected predictors at each iteration (the order of the selected predictors)\n",
    "tb = np.zeros(ncol) # A vector to store the BIC of the selected model at each iteration\n",
    "p = 0 # Iteration idex\n",
    "\n",
    "while len(psel) != ncol: # Repeat below until the model includes all the predictors\n",
    "    tb0 = np.zeros((len(pcand),2)) # Store Rsquare(s) and BIC(s) of the models under consideration at each iteration\n",
    "\n",
    "    for i in range(0,len(pcand)):\n",
    "        psel0 = psel + [pcand[i]] # \"psel0\" is a temporary version of psel which includes one of the predictors in pcan and those in psel\n",
    "        # Caution: \"+\" combines two lists, but not a list and an integer (i.e pcan[i])\n",
    "        XX = X[:,psel0]\n",
    "        XX = sm.add_constant(XX)\n",
    "        model = sm.OLS(Y, XX)\n",
    "        res = model.fit()\n",
    "        tb0[i,:] = [res.rsquared, res.bic]\n",
    "    \n",
    "    ind = np.argmax(tb0[:,0]) # Find the regressor that results in the largest Rsquare when added to the model\n",
    "    psel = psel + [pcand[ind]] # Add the selected regressor to psel\n",
    "    pcand.remove(pcand[ind]) # Remove the selected regressor from pcand\n",
    "    tb[p] =  tb0[ind,1] # Store the BIC of the selected model at this iteration\n",
    "    p += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8108bc9f-0eb7-4938-8008-d3f1997526a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selected \n",
    "psel_forward = psel.copy()\n",
    "tb_forward = tb.copy()\n",
    "\n",
    "model_selected_forward_bic = psel_forward[:(np.argmin(tb)+1)]\n",
    "BIC_forward = min(tb)\n",
    "model_selected_var_names_forward_bic = [raw_data.columns[x] for x in model_selected_forward_bic]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd684b5e-00b8-437c-b25e-696cace589a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Forward Selection AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "192d1020-c129-4ca3-a0f2-2c4814bbe29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcand = list(range(ncol)) # A list to keep track of the set of predictors left to add to the model at each iteration\n",
    "psel = [] # A list to keep track of the selected predictors at each iteration (the order of the selected predictors)\n",
    "tb = np.zeros(ncol) # A vector to store the BIC of the selected model at each iteration\n",
    "p = 0 # Iteration idex\n",
    "\n",
    "while len(psel) != ncol: # Repeat below until the model includes all the predictors\n",
    "    tb0 = np.zeros((len(pcand),2)) # Store Rsquare(s) and BIC(s) of the models under consideration at each iteration\n",
    "\n",
    "    for i in range(0,len(pcand)):\n",
    "        psel0 = psel + [pcand[i]] # \"psel0\" is a temporary version of psel which includes one of the predictors in pcan and those in psel\n",
    "        # Caution: \"+\" combines two lists, but not a list and an integer (i.e pcan[i])\n",
    "        XX = X[:,psel0]\n",
    "        XX = sm.add_constant(XX)\n",
    "        model = sm.OLS(Y, XX)\n",
    "        res = model.fit()\n",
    "        tb0[i,:] = [res.rsquared, res.aic]\n",
    "    \n",
    "    ind = np.argmax(tb0[:,0]) # Find the regressor that results in the largest Rsquare when added to the model\n",
    "    psel = psel + [pcand[ind]] # Add the selected regressor to psel\n",
    "    pcand.remove(pcand[ind]) # Remove the selected regressor from pcand\n",
    "    tb[p] =  tb0[ind,1] # Store the BIC of the selected model at this iteration\n",
    "    p += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f85d74e2-4de8-4652-8433-aa140c6db849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selected \n",
    "psel_forward = psel.copy()\n",
    "tb_forward = tb.copy()\n",
    "\n",
    "model_selected_forward_aic = psel_forward[:(np.argmin(tb)+1)]\n",
    "AIC_forward = min(tb)\n",
    "model_selected_var_names_forward_aic = [X_col[x] for x in model_selected_forward_aic]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957b5e52-7f9e-4c25-8046-91507e2899a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Backward Selection BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31a9dde1-4bfd-4da8-b3e7-2f1a194bad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcand = list(range(ncol)) \n",
    "psel = [] \n",
    "tb = np.zeros(ncol) \n",
    "p = 0 \n",
    "\n",
    "while len(psel) != ncol: \n",
    "    tb0 = np.zeros((len(pcand),2)) \n",
    "\n",
    "    for i in range(0,len(pcand)):\n",
    "        psel0 = pcand.copy() # line 1\n",
    "        psel0.remove(psel0[i]) # line 2\n",
    "        XX = X[:,psel0]\n",
    "        XX = sm.add_constant(XX)\n",
    "        res = sm.OLS(Y, XX).fit()\n",
    "        tb0[i,:] = [res.rsquared, res.bic]\n",
    "    \n",
    "    ind = np.argmax(tb0[:,0]) \n",
    "    psel = psel + [pcand[ind]] \n",
    "    pcand.remove(pcand[ind]) \n",
    "    tb[p] =  tb0[ind,1] \n",
    "    p += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b82b25-e51a-4e5c-b978-81481b1e6044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selected \n",
    "psel_backward = psel.copy()\n",
    "tb_backward = tb.copy()\n",
    "\n",
    "model_selected_backward = psel_backward[np.argmin(tb):]\n",
    "BIC_forward = min(tb)\n",
    "model_selected_var_names_backward_bic = [X_col[x] for x in model_selected_backward]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d551f-4a46-4d90-afd7-f67015733170",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Backward Selection BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cf5cfd0-8a4f-481b-bc9b-bd5b5f39265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcand = list(range(ncol)) \n",
    "psel = [] \n",
    "tb = np.zeros(ncol) \n",
    "p = 0 \n",
    "\n",
    "while len(psel) != ncol: \n",
    "    tb0 = np.zeros((len(pcand),2)) \n",
    "\n",
    "    for i in range(0,len(pcand)):\n",
    "        psel0 = pcand.copy() # line 1\n",
    "        psel0.remove(psel0[i]) # line 2\n",
    "        XX = X[:,psel0]\n",
    "        XX = sm.add_constant(XX)\n",
    "        res = sm.OLS(Y, XX).fit()\n",
    "        tb0[i,:] = [res.rsquared, res.aic]\n",
    "    \n",
    "    ind = np.argmax(tb0[:,0]) \n",
    "    psel = psel + [pcand[ind]] \n",
    "    pcand.remove(pcand[ind]) \n",
    "    tb[p] =  tb0[ind,1] \n",
    "    p += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fc00784-4c88-4c57-a2d4-63980a0ee96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selected \n",
    "psel_backward = psel.copy()\n",
    "tb_backward = tb.copy()\n",
    "\n",
    "model_selected_backward_aic = psel_backward[np.argmin(tb):]\n",
    "AIC_backward = min(tb)\n",
    "model_selected_var_names_backward_aic = [X_col[x] for x in model_selected_backward]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc66769-486a-4f84-860c-d6b5a2fb4c0f",
   "metadata": {},
   "source": [
    "## <font color='Blue'> LASSO Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e7d3041-ef88-4620-aced-e2dedeaac712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from sklearn.linear_model import LassoLarsCV, LassoLarsIC\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Initalize variables\n",
    "Y = raw_data[Y_col].values\n",
    "X = raw_data[X_col].values \n",
    "eps = 1e-10\n",
    "\n",
    "# Standardize Values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_no_scale = X.copy()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36670212-9e33-4870-b8d9-d9cf895f7b24",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55dbadfd-10b7-41da-aaf3-b022c5c517d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  FutureWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.213e+00, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.213e+00, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.913e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.107e-01, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.687e-01, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.555e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=2.554e-01, previous alpha=4.636e-02, with an active set of 16 regressors.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.681e+00, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.145e+00, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.145e+00, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.879e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.208e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.208e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=4.156e-01, previous alpha=3.806e-01, with an active set of 13 regressors.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.268e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.031e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.100e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=4.012e-01, previous alpha=3.408e-01, with an active set of 15 regressors.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.493e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.418e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=6.305e-01, previous alpha=6.177e-01, with an active set of 10 regressors.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.112e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.635e-01, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.635e-01, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.212e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.212e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=6.396e-02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.359e-02, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.359e-02, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=8.899e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.797e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.797e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "lascv = LassoLarsCV(cv=5).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d770cd54-40e7-4d74-908b-e9cea104022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = lascv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db1b4da9-2d70-4a27-b898-8328602a3476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+04, tolerance: 5.332e+03\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    }
   ],
   "source": [
    "las = linear_model.Lasso(alpha=alpha).fit(X,Y) # alpha is the tuning parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb9ba5f-4ead-4c0c-9929-31fe297a7d1d",
   "metadata": {},
   "source": [
    "### BIC and AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b72babb2-56a8-4d07-b3cf-0f207f747c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  FutureWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.860e-02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.115e-02, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.115e-02, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  FutureWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.860e-02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.115e-02, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.115e-02, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "lasic_bic = LassoLarsIC(criterion='bic').fit(X, Y)\n",
    "lasic_aic = LassoLarsIC(criterion='aic').fit(X, Y)\n",
    "\n",
    "# Access the Lasso estimates at the alpha selected by AIC and BIC\n",
    "lasso_aic = lasic_aic.coef_\n",
    "lasso_bic = lasic_bic.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e21257-3ce6-4f18-b203-4b906a5f6ecf",
   "metadata": {},
   "source": [
    "## <font color='Blue'> Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39222137-f5da-43a2-a396-3673393af321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso CV tuned coefficients\n",
      "AtBat: -289.68015553142163\n",
      "Hits: 326.13334412407454\n",
      "HmRun: 24.678012386498484\n",
      "Runs: -47.52927346140862\n",
      "RBI: -12.523098402873481\n",
      "Walks: 129.3901222583898\n",
      "Years: -23.23786337394064\n",
      "CAtBat: -293.2480211852585\n",
      "CHits: 39.6532120908762\n",
      "CHmRun: 0.0\n",
      "CRuns: 448.0022026406147\n",
      "CRBI: 228.88684776279894\n",
      "CWalks: -206.60995488166998\n",
      "PutOuts: 78.98221295590994\n",
      "Assists: 49.107127218325225\n",
      "Errors: -20.774453719972843\n",
      "League_A: -28.132637443706567\n",
      "League_N: 2.9661782113726768e-12\n",
      "Division_E: 58.05706332410207\n",
      "Division_W: -3.88777645480418e-12\n",
      "NewLeague_A: 9.250351296346711\n",
      "NewLeague_N: -0.0\n",
      "\n",
      "Lasso AIC coefficients\n",
      "AtBat: -243.8682072471136\n",
      "Hits: 266.4012775256097\n",
      "HmRun: 0.0\n",
      "Runs: 0.0\n",
      "RBI: 0.0\n",
      "Walks: 106.60985957892501\n",
      "Years: -47.532008416057835\n",
      "CAtBat: 0.0\n",
      "CHits: 0.0\n",
      "CHmRun: 47.51250671279551\n",
      "CRuns: 230.64749688598638\n",
      "CRBI: 121.58874342435858\n",
      "CWalks: -151.07487185821017\n",
      "PutOuts: 76.98509398877259\n",
      "Assists: 27.894786291910307\n",
      "Errors: -14.454133446526885\n",
      "League_A: -16.402899640209895\n",
      "League_N: 0.0\n",
      "Division_E: 59.575621105326555\n",
      "Division_W: 0.0\n",
      "NewLeague_A: 0.0\n",
      "NewLeague_N: 0.0\n",
      "\n",
      "Lasso BIC coefficients\n",
      "AtBat: 0.0\n",
      "Hits: 83.79144232468326\n",
      "HmRun: 0.0\n",
      "Runs: 0.0\n",
      "RBI: 0.0\n",
      "Walks: 47.962180081250054\n",
      "Years: 0.0\n",
      "CAtBat: 0.0\n",
      "CHits: 0.0\n",
      "CHmRun: 0.0\n",
      "CRuns: 67.30564772853845\n",
      "CRBI: 133.7558746878184\n",
      "CWalks: 0.0\n",
      "PutOuts: 61.11779895536156\n",
      "Assists: 0.0\n",
      "Errors: 0.0\n",
      "League_A: 0.0\n",
      "League_N: 0.0\n",
      "Division_E: 51.0653178206533\n",
      "Division_W: 0.0\n",
      "NewLeague_A: 0.0\n",
      "NewLeague_N: 0.0\n",
      "\n",
      "Variables Selected using Forwards Selection with BIC\n",
      "['CRBI', 'Hits', 'PutOuts', 'League_N', 'AtBat', 'Walks']\n",
      "BIC score: 3812.7479908452106\n",
      "\n",
      "Variables Selected Forwards Selection using AIC\n",
      "['CRBI', 'Hits', 'PutOuts', 'Division_E', 'AtBat', 'Walks', 'CWalks', 'CRuns', 'CAtBat', 'Assists']\n",
      "AIC score: 3777.619775012732\n",
      "\n",
      "Variables Selected Backwards Selection using BIC\n",
      "['CAtBat', 'CRBI', 'CWalks', 'Division_E', 'Walks', 'AtBat', 'PutOuts', 'Hits', 'CRuns']\n",
      "BIC score: 3812.7479908452106\n",
      "\n",
      "Variables Selected Backwards Selection using AIC\n",
      "['CAtBat', 'CRBI', 'CWalks', 'Division_E', 'Walks', 'AtBat', 'PutOuts', 'Hits', 'CRuns']\n",
      "AIC score: 3777.619775012732\n"
     ]
    }
   ],
   "source": [
    "# Summary for Lasso CV\n",
    "print('Lasso CV tuned coefficients')\n",
    "for index, name in enumerate(X_col):\n",
    "    print(f'{name}: {las.coef_[index]}')\n",
    "\n",
    "\n",
    "# Summary for Lasso AIC\n",
    "print('\\nLasso AIC coefficients')\n",
    "for index, name in enumerate(X_col):\n",
    "    print(f'{name}: {lasso_aic[index]}') \n",
    "\n",
    "# Summary for Lasso BIC\n",
    "print('\\nLasso BIC coefficients')\n",
    "for index, name in enumerate(X_col):\n",
    "    print(f'{name}: {lasso_bic[index]}')\n",
    "\n",
    "# Summary for Forwards selection\n",
    "print('\\nVariables Selected using Forwards Selection with BIC')\n",
    "print(model_selected_var_names_forward_bic)\n",
    "print(f'BIC score: {BIC_forward}')\n",
    "\n",
    "print('\\nVariables Selected Forwards Selection using AIC')\n",
    "print(model_selected_var_names_forward_aic)\n",
    "print(f'AIC score: {AIC_forward}')\n",
    "\n",
    "# Summary for Backwards selection\n",
    "print('\\nVariables Selected Backwards Selection using BIC')\n",
    "print(model_selected_var_names_backward_bic)\n",
    "print(f'BIC score: {BIC_forward}')\n",
    "\n",
    "print('\\nVariables Selected Backwards Selection using AIC')\n",
    "print(model_selected_var_names_backward_aic)\n",
    "print(f'AIC score: {AIC_forward}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c0508fe-1876-466a-8bbd-c04d8b1fc1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x560 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building graphs to display results from AIC and BIC\n",
    "def plot_ic_criterion(model, name, color): \n",
    "    alpha_ = model.alpha_ + eps\n",
    "    alphas_ = model.alphas_ + eps\n",
    "    criterion_ = model.criterion_ # BIC or AIC values over the alpha values\n",
    "    plt.plot(np.log10(alphas_), criterion_, '--', color=color,\n",
    "             linewidth=3, label='%s' % name)\n",
    "    plt.axvline(np.log10(alpha_), color=color, linewidth=3,\n",
    "                label='$\\lambda$ selected by %s ' % name)\n",
    "    plt.xlabel('Log($\\lambda$)')\n",
    "    plt.ylabel('Criterion Value')\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(8, 7), dpi=80)\n",
    "plot_ic_criterion(lasic_aic, 'AIC', 'b')\n",
    "plot_ic_criterion(lasic_bic, 'BIC', 'r')\n",
    "plt.legend()\n",
    "plt.title('Model Selection by Information Criteria')\n",
    "#plt.show()\n",
    "plt.savefig('lasso.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
